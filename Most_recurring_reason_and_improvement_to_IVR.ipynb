{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnN7_L4Xp7ej",
        "outputId": "3445a65b-c807-4367-aaa3-267ec74a68a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import re"
      ],
      "metadata": {
        "id": "gR7eW3h-qx2q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('/content/calls.csv', escapechar='\\\\')\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Error reading CSV: {e}\")\n",
        "    line_number = int(str(e).split('row ')[1].split(',')[0])\n",
        "    print(f\"Problematic line number: {line_number}\")\n",
        "    with open('/content/calls.csv', 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            if i == line_number - 1:\n",
        "                print(f\"Problematic line: {line}\")\n",
        "                break\n",
        "\n",
        "def preprocess_transcripts(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in nltk.word_tokenize(text) if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "if 'call_transcript' in df.columns:\n",
        "    df['processed_transcript'] = df['call_transcript'].apply(preprocess_transcripts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJkfJjtaqK9r",
        "outputId": "028b55a5-034a-4466-8131-9744be053d65"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(df['processed_transcript'])\n",
        "\n",
        "lda_model = LatentDirichletAllocation(n_components=5, random_state=42)\n",
        "lda_model.fit(tfidf_matrix)\n",
        "\n",
        "def display_topics(model, feature_names, num_top_words):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}:\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]))\n",
        "\n",
        "tfidf_feature_names = vectorizer.get_feature_names_out()\n",
        "display_topics(lda_model, tfidf_feature_names, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmx1Oe-br40x",
        "outputId": "fa323aac-c98e-4370-c1b7-3f5dec992b59"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:\n",
            "standby list earlier forecast weather waitlist case chance backup really\n",
            "Topic 1:\n",
            "tomorrow sir pm meeting delay frustration issues la apologize delayed\n",
            "Topic 2:\n",
            "delay refund voucher experience delays delayed missed travel hours make\n",
            "Topic 3:\n",
            "wanted seat check time double london upgrade chicago thanks sure\n",
            "Topic 4:\n",
            "change fee work date need monday day typing wednesday okay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def extract_keywords(text, nlp):\n",
        "    doc = nlp(text)\n",
        "    keywords = [chunk.text for chunk in doc.noun_chunks]\n",
        "    return keywords\n",
        "df['keywords'] = df['processed_transcript'].apply(lambda x: extract_keywords(x, nlp))\n",
        "\n",
        "keyword_counter = Counter([keyword for keywords in df['keywords'] for keyword in keywords])\n",
        "print(keyword_counter.most_common(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmjJJl8XsCBx",
        "outputId": "b2a36537-03b2-43e1-f9f7-8067c30c4be4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('i', 306118), ('you', 170881), ('flight', 78342), ('anything', 74649), ('agent thank', 72396), ('that', 52868), ('customer', 51902), ('today customer', 40429), ('agent', 39092), ('united airlines', 38967)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/df_final.csv')"
      ],
      "metadata": {
        "id": "KDd3ifRv-I17"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['agent_tone_encoded'] = le.fit_transform(df['agent_tone'])\n",
        "df['customer_tone_encoded'] = le.fit_transform(df['customer_tone'])\n",
        "\n",
        "negative_tone = df[(df['average_sentiment'] < 0) & (df['customer_tone_encoded'] > 2)]\n",
        "print(negative_tone['primary_call_reason'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFOFPDFrsHqL",
        "outputId": "b5c5b680-4b0a-4ea8-e5ba-29f3bfd8107d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "primary_call_reason\n",
            "Flight Changes                  6081\n",
            "Loyalty Program & Membership    1992\n",
            "Seat Preferences & Upgrades     1629\n",
            "Post-Flight Issues              1557\n",
            "Booking and Boarding            1380\n",
            "Customer Support                1235\n",
            "Other                            359\n",
            "Special Services                  66\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}